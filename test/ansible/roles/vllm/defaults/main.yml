---
# Default variables for vllm role

# Container settings
vllm_container_name: vllm-benchmark
vllm_image: vllm/vllm-openai:latest
vllm_port: 8000

# Model settings
vllm_model_id: ""  # Required - must be set
vllm_tensor_parallel: 1
vllm_max_model_len: 4096
vllm_gpu_memory_utilization: 0.90
vllm_trust_remote_code: false

# Optional settings
# vllm_dtype: "auto"  # auto, half, float16, bfloat16
# vllm_quantization: ""  # awq, gptq, squeezellm
# vllm_hf_token: ""  # HuggingFace token for gated models

# Resource settings
vllm_shm_size: "16g"
vllm_cache_dir: /root/.cache/huggingface

# Startup settings
vllm_startup_retries: 60  # Wait up to 10 minutes for model loading
vllm_startup_delay: 10

# Control flags
vllm_force_pull: false
vllm_force_restart: false
